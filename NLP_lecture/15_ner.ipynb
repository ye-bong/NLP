{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 개체명 인식\n",
    "\n",
    "* 도메인 또는 목적에 맞게 개체명을 인식시킴  \n",
    "\n",
    "* 개체명의 종류  \n",
    "  - 분석 목적에 맞춰서 데이터 셋 자체 구축 + 개체명 인식 모델 훈련  \n",
    "  - 조직, 사람, 지역과 관련된 개체명 인식 => 기존에 훈련된 모델을 갖고 분석 가능  \n",
    "\n",
    "* BIO 표현  \n",
    "  - B 시작 / I 내부 / O 기타, 그외  \n",
    "\n",
    "* 훈련 데이터셋을 만드는 방법\n",
    "  - 구문 분석을 활용 (특정 부분에 등장하는 구문에서 데이터 추출: 라벨링)  \n",
    "  - 기존에 훈련된 모델의 결과를 새로운 데이터에 적용하여 라벨링을 달고, 그 데이터를 다시 훈련 데이터에 포함하여 모델 훈련 방식  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jeff</td>\n",
       "      <td>B-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dean</td>\n",
       "      <td>I-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>computer</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>scientist</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>at</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Google</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>California</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tokens   Tags\n",
       "0        Jeff  B-PER\n",
       "1        Dean  I-PER\n",
       "2          is      O\n",
       "3           a      O\n",
       "4    computer      O\n",
       "5   scientist      O\n",
       "6          at      O\n",
       "7      Google  B-ORG\n",
       "8          in      O\n",
       "9  California  B-LOC"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks = \"Jeff Dean is a computer scientist at Google in California\".split()\n",
    "lbls = [\"B-PER\", \"I-PER\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"O\", \"B-LOC\"]\n",
    "df = pd.DataFrame(data=[toks, lbls], index=['Tokens', 'Tags'])\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/12.%20RNN%20Sequence%20Labeling/dataset/train.txt\", filename=\"train.txt\" )\n",
    "\n",
    "f = open('train.txt', 'r')\n",
    "tagged_sentences = []\n",
    "sentence = []\n",
    "\n",
    "for line in f :\n",
    "    if len(line) == 0 or line.startswith('-DOCSTART') or line[0] == \"\\n\":\n",
    "        if len(sentence) > 0 :\n",
    "            tagged_sentences.append(sentence)\n",
    "            sentence = []\n",
    "        continue\n",
    "    splits = line.split(' ')\n",
    "    splits[-1] = re.sub(r'\\n', '', splits[-1])\n",
    "    word = splits[0].lower()\n",
    "    sentence.append([word, splits[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['eu', 'B-ORG'],\n",
       "  ['rejects', 'O'],\n",
       "  ['german', 'B-MISC'],\n",
       "  ['call', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['boycott', 'O'],\n",
       "  ['british', 'B-MISC'],\n",
       "  ['lamb', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['peter', 'B-PER'], ['blackburn', 'I-PER']],\n",
       " [['brussels', 'B-LOC'], ['1996-08-22', 'O']],\n",
       " [['the', 'O'],\n",
       "  ['european', 'B-ORG'],\n",
       "  ['commission', 'I-ORG'],\n",
       "  ['said', 'O'],\n",
       "  ['on', 'O'],\n",
       "  ['thursday', 'O'],\n",
       "  ['it', 'O'],\n",
       "  ['disagreed', 'O'],\n",
       "  ['with', 'O'],\n",
       "  ['german', 'B-MISC'],\n",
       "  ['advice', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['consumers', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['shun', 'O'],\n",
       "  ['british', 'B-MISC'],\n",
       "  ['lamb', 'O'],\n",
       "  ['until', 'O'],\n",
       "  ['scientists', 'O'],\n",
       "  ['determine', 'O'],\n",
       "  ['whether', 'O'],\n",
       "  ['mad', 'O'],\n",
       "  ['cow', 'O'],\n",
       "  ['disease', 'O'],\n",
       "  ['can', 'O'],\n",
       "  ['be', 'O'],\n",
       "  ['transmitted', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['sheep', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['germany', 'B-LOC'],\n",
       "  [\"'s\", 'O'],\n",
       "  ['representative', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['european', 'B-ORG'],\n",
       "  ['union', 'I-ORG'],\n",
       "  [\"'s\", 'O'],\n",
       "  ['veterinary', 'O'],\n",
       "  ['committee', 'O'],\n",
       "  ['werner', 'B-PER'],\n",
       "  ['zwingmann', 'I-PER'],\n",
       "  ['said', 'O'],\n",
       "  ['on', 'O'],\n",
       "  ['wednesday', 'O'],\n",
       "  ['consumers', 'O'],\n",
       "  ['should', 'O'],\n",
       "  ['buy', 'O'],\n",
       "  ['sheepmeat', 'O'],\n",
       "  ['from', 'O'],\n",
       "  ['countries', 'O'],\n",
       "  ['other', 'O'],\n",
       "  ['than', 'O'],\n",
       "  ['britain', 'B-LOC'],\n",
       "  ['until', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['scientific', 'O'],\n",
       "  ['advice', 'O'],\n",
       "  ['was', 'O'],\n",
       "  ['clearer', 'O'],\n",
       "  ['.', 'O']]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 개수 :  14041\n"
     ]
    }
   ],
   "source": [
    "print(\"전체 샘플 개수 : \", len(tagged_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['eu', 'B-ORG'],\n",
       " ['rejects', 'O'],\n",
       " ['german', 'B-MISC'],\n",
       " ['call', 'O'],\n",
       " ['to', 'O'],\n",
       " ['boycott', 'O'],\n",
       " ['british', 'B-MISC'],\n",
       " ['lamb', 'O'],\n",
       " ['.', 'O']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.'),\n",
       " ('B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence, tag_info = zip(*tagged_sentences[0])\n",
    "sentence, tag_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, ner_tags = [], []\n",
    "for tagged_sentence in tagged_sentences:\n",
    "    sentence, tag_info = zip(*tagged_sentence)\n",
    "    sentences.append(list(sentence))\n",
    "    ner_tags.append(list(tag_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "개체명 인식 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 4000\n",
    "src_tokenizer = Tokenizer(num_words=4000, oov_token='OOV')\n",
    "src_tokenizer.fit_on_texts(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(ner_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 :  4000\n",
      "개체명 태깅 정보의 집합의 크기 :  10\n"
     ]
    }
   ],
   "source": [
    "tag_size = len(tar_tokenizer.word_index) + 1 \n",
    "print('단어 집합의 크기 : ' ,  vocab_size)\n",
    "print('개체명 태깅 정보의 집합의 크기 : ', tag_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수인코딩 : {\"사과\" : 1 , }\n",
    "X_train = src_tokenizer.texts_to_sequences(sentences)\n",
    "y_train = tar_tokenizer.texts_to_sequences(ner_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.']\n",
      "[989, 1, 205, 629, 7, 3939, 216, 1, 3]\n",
      "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']\n",
      "[4, 1, 7, 1, 1, 1, 7, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0])\n",
    "print(X_train[0])\n",
    "print(ner_tags[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = src_tokenizer.index_word\n",
    "index_to_ner = tar_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존 문장 : ['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.']\n",
      "빈도수가 낮은 단어, OOV 처리된 부분 확인 : ['eu', 'OOV', 'german', 'call', 'to', 'boycott', 'british', 'OOV', '.']\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for index in X_train[0]:\n",
    "    decoded.append(index_to_word[index])\n",
    "\n",
    "print(f\"기존 문장 : {sentences[0]}\")\n",
    "print(f\"빈도수가 낮은 단어, OOV 처리된 부분 확인 : {decoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 데이터의 길이를 통일 하기 위해  padding을 적용\n",
    "\n",
    "max_len = 70 # 세밀한 분석을 위해서는 텍스트 데이터 EDA를 통해서 max_len / median_len / mean_len 을 보고서 파라미터의 값을 설정함\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=max_len)\n",
    "y_train = pad_sequences(y_train, padding='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test , y_train , y_test = train_test_split(X_train, y_train, test_size=.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원핫인코딩\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=tag_size)\n",
    "y_test = to_categorical(y_test, num_classes=tag_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 문장의 크기 : (9828, 70)\n",
      "훈련 샘플 레이블의 크기 : (9828, 70, 10)\n",
      "테스트 샘플 문장의 크기 : (4213, 70)\n",
      "테스트 샘플 레이블의 크기 : (4213, 70, 10)\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\n",
    "print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))\n",
    "print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\n",
    "print('테스트 샘플 레이블의 크기 : {}'.format(y_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping , ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import random as tf_random , constant_initializer\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def reset_model_random():\n",
    "    random_seed_num = 0\n",
    "    tf_random.set_seed(random_seed_num)\n",
    "    np.random.seed(random_seed_num)\n",
    "    random.seed(random_seed_num)\n",
    "    constant_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "hidden_units = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = vocab_size , output_dim = embedding_dim, \n",
    "                    input_length = max_len , mask_zero = True))\n",
    "model.add(Bidirectional(LSTM(hidden_units, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(tag_size, activation = 'softmax')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 70, 128)           512000    \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 70, 256)           263168    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " time_distributed (TimeDist  (None, 70, 10)            2570      \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 777738 (2.97 MB)\n",
      "Trainable params: 777738 (2.97 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "77/77 [==============================] - 33s 376ms/step - loss: 1.0105 - accuracy: 0.8200 - val_loss: 0.6744 - val_accuracy: 0.8359\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 30s 392ms/step - loss: 0.5529 - accuracy: 0.8385 - val_loss: 0.4450 - val_accuracy: 0.8633\n",
      "Epoch 3/10\n",
      "77/77 [==============================] - 30s 390ms/step - loss: 0.3914 - accuracy: 0.8805 - val_loss: 0.3365 - val_accuracy: 0.9027\n",
      "Epoch 4/10\n",
      "77/77 [==============================] - 31s 398ms/step - loss: 0.2829 - accuracy: 0.9175 - val_loss: 0.2521 - val_accuracy: 0.9289\n",
      "Epoch 5/10\n",
      "77/77 [==============================] - 31s 399ms/step - loss: 0.2084 - accuracy: 0.9387 - val_loss: 0.1982 - val_accuracy: 0.9441\n",
      "Epoch 6/10\n",
      "77/77 [==============================] - 30s 390ms/step - loss: 0.1630 - accuracy: 0.9521 - val_loss: 0.1773 - val_accuracy: 0.9495\n",
      "Epoch 7/10\n",
      "77/77 [==============================] - 30s 395ms/step - loss: 0.1343 - accuracy: 0.9604 - val_loss: 0.1668 - val_accuracy: 0.9531\n",
      "Epoch 8/10\n",
      "77/77 [==============================] - 31s 397ms/step - loss: 0.1161 - accuracy: 0.9662 - val_loss: 0.1623 - val_accuracy: 0.9531\n",
      "Epoch 9/10\n",
      "77/77 [==============================] - 31s 397ms/step - loss: 0.1036 - accuracy: 0.9699 - val_loss: 0.1610 - val_accuracy: 0.9558\n",
      "Epoch 10/10\n",
      "77/77 [==============================] - 31s 399ms/step - loss: 0.0916 - accuracy: 0.9733 - val_loss: 0.1720 - val_accuracy: 0.9553\n"
     ]
    }
   ],
   "source": [
    "reset_model_random()\n",
    "\n",
    "es = EarlyStopping(patience=2, monitor='accuracy')\n",
    "mc = ModelCheckpoint(f\"./model/NER_model.h5\", save_best_only=True)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer=Adam(0.001)\n",
    "              , metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=128 , epochs= 10 ,\n",
    "                    validation_data=(X_test, y_test), callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 훈련 히스토리 관리 방법\n",
    "  \n",
    "- log 파일\n",
    "- 모델을 좀 더 관리하는 경우에는 DB에 모델 정보를 관리하는 테이블에 저장\n",
    "  \n",
    "모델 서빙 방법/시점에서 활용 \n",
    "1. 특정 일자마다 모델 재훈련을 한다면, 모델 훈련 (평균) 소요시간 이후에 모델의 결과를 DB에서 확인  \n",
    "2. 모델 결과/평가 기준이 확인  \n",
    "   if 평가 기준 = 미달 :  \n",
    "      모델 재훈련을 하는 이메일/알람 => 운영자 혹은 담당자가 재훈련(모델 아키텍처부터 재설계 후 모델 재훈련)  \n",
    "   else :    \n",
    "      저장된 모델을 운영 서버에 적용하도록 함   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.0104928016662598,\n",
       "  0.5528500080108643,\n",
       "  0.39142704010009766,\n",
       "  0.2829253375530243,\n",
       "  0.20840083062648773,\n",
       "  0.16298261284828186,\n",
       "  0.13434351980686188,\n",
       "  0.11606518179178238,\n",
       "  0.10362490266561508,\n",
       "  0.09163041412830353],\n",
       " 'accuracy': [0.8199923038482666,\n",
       "  0.8385356068611145,\n",
       "  0.8805081844329834,\n",
       "  0.9174547791481018,\n",
       "  0.938693106174469,\n",
       "  0.9520843029022217,\n",
       "  0.9604144096374512,\n",
       "  0.9661895036697388,\n",
       "  0.9699485301971436,\n",
       "  0.9733155965805054],\n",
       " 'val_loss': [0.6744264960289001,\n",
       "  0.44497713446617126,\n",
       "  0.3364686667919159,\n",
       "  0.2520807385444641,\n",
       "  0.1982152760028839,\n",
       "  0.17729799449443817,\n",
       "  0.166817307472229,\n",
       "  0.1623183786869049,\n",
       "  0.16096438467502594,\n",
       "  0.17201517522335052],\n",
       " 'val_accuracy': [0.8359054327011108,\n",
       "  0.8633451461791992,\n",
       "  0.9026764631271362,\n",
       "  0.9288808107376099,\n",
       "  0.9440500736236572,\n",
       "  0.9495182633399963,\n",
       "  0.9531252384185791,\n",
       "  0.9530923366546631,\n",
       "  0.9557605385780334,\n",
       "  0.955348789691925]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 훈련 히스토리 : log 파일로 남기거나 혹은 모델을 좀 더 관리하는 경우에는 DB에 모델 정보를 관리하는 테이블에 저장\n",
    "\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 3s 19ms/step - loss: 0.1717 - accuracy: 0.9553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1717061996459961, 0.955348789691925]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "단어             |실제값  |예측값\n",
      "===================================\n",
      "attendance       :o       o\n",
      ":                :o       o\n",
      "OOV              :o       o\n"
     ]
    }
   ],
   "source": [
    "# 예측하기\n",
    "y_predicted = model.predict(np.array([X_test[0]]))\n",
    "\n",
    "# 확률 벡터를 정수 레이블로 변경\n",
    "y_predicted = np.argmax(y_predicted, axis= -1)\n",
    "\n",
    "# 원-핫 벡터를 정수 인코딩으로 변경\n",
    "labels = np.argmax(y_test[0], -1)\n",
    "\n",
    "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
    "print(35 * \"=\")\n",
    "\n",
    "for word, tag, pred in zip(X_test[0], labels, y_predicted[0]):\n",
    "    if word != 0 : \n",
    "        print(\"{:17}:{:7} {}\".format(index_to_word[word], index_to_ner[tag], index_to_ner[pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "단어             |실제값  |예측값\n",
      "===================================\n",
      "\"                :o       o\n",
      "i                :o       o\n",
      "looked           :o       o\n",
      "at               :o       o\n",
      "it               :o       o\n",
      "as               :o       o\n",
      "not              :o       o\n",
      "a                :o       o\n",
      "first            :o       o\n",
      "round            :o       o\n",
      "match            :o       o\n",
      ",                :o       o\n",
      "just             :o       o\n",
      "a                :o       o\n",
      "great            :o       o\n",
      "challenge        :o       o\n",
      "for              :o       o\n",
      "me               :o       o\n",
      ",                :o       o\n",
      "\"                :o       o\n",
      "said             :o       o\n",
      "coetzer          :b-per   b-per\n",
      ",                :o       o\n",
      "24               :o       o\n",
      ".                :o       o\n",
      "\"                :o       o\n"
     ]
    }
   ],
   "source": [
    "# 예측하기\n",
    "y_predicted = model.predict(np.array([X_test[90]]))\n",
    "\n",
    "# 확률 벡터를 정수 레이블로 변경\n",
    "y_predicted = np.argmax(y_predicted, axis= -1)\n",
    "\n",
    "# 원-핫 벡터를 정수 인코딩으로 변경\n",
    "labels = np.argmax(y_test[90], -1)\n",
    "\n",
    "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
    "print(35 * \"=\")\n",
    "\n",
    "for word, tag, pred in zip(X_test[90], labels, y_predicted[0]):\n",
    "    if word != 0 : \n",
    "        print(\"{:17}:{:7} {}\".format(index_to_word[word], index_to_ner[tag], index_to_ner[pred]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이후에 할 수 있는 분석 작업들\n",
    "\n",
    "1. 새로운 데이터가 들어오면, 개체명을 예측해서 그 값을 추출하여 통계적 분석(Count)\n",
    "   - word 자체에 대한 카운팅 (예: 'coetzer')\n",
    "   - 개체명 결과(라벨)에 대한 카운팅 (예 : 'b-per/I-per' / 'b-org/I-per' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
