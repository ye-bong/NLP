{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gpt 모델 아키텍처\n",
    "\n",
    "- 목적 : 한글 영어 번역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook, trange\n",
    "\n",
    "from tensorflow.keras.layers import Dense , Input \n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from tensorflow.keras.models import Model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련 파라미터 값\n",
    "ENCODER_LEN = 61\n",
    "DECODER_LEN = ENCODER_LEN\n",
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "N_EPRCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터셋 로딩 \n",
    "import urllib3\n",
    "import zipfile\n",
    "import shutil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "http = urllib3.PoolManager()\n",
    "url = \"https://raw.githubusercontent.com/Huffon/pytorch-transformer-kor-eng/master/data/corpus.csv\"\n",
    "filename = './data/corpus.csv'\n",
    "path = os.getcwd()\n",
    "zipfilename = os.path.join(path, filename)\n",
    "with http.request('GET', url, preload_content = False ) as r , open(zipfilename, 'wb') as out_file:\n",
    "    shutil.copyfileobj(r, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.read_csv('./data/corpus.csv')\n",
    "\n",
    "total_df.rename(columns={\"english\":'SRC', \"korean\":'TRG'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRG</th>\n",
       "      <th>SRC</th>\n",
       "      <th>src_len</th>\n",
       "      <th>tar_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>나는 매일 저녁 배트를 만나러 다락방으로 가요.</td>\n",
       "      <td>I go to the attic every evening to meet Bat.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>선생님 이문장이 이해가 안 가요.</td>\n",
       "      <td>Sir, I don't understand this sentence here.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>컴퓨터를 시작하면 시간이 너무 빠르게 가요.</td>\n",
       "      <td>Time flies when you start using the computer.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>나는 오늘 자정에 한국으로 돌아 가요.</td>\n",
       "      <td>I'm going back to Korea today at midnight.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>나는 일어나자마자 화장실에 가요.</td>\n",
       "      <td>I go to bathroom as soon as I wake up.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          TRG                                            SRC  \\\n",
       "0  나는 매일 저녁 배트를 만나러 다락방으로 가요.   I go to the attic every evening to meet Bat.   \n",
       "1          선생님 이문장이 이해가 안 가요.    Sir, I don't understand this sentence here.   \n",
       "2    컴퓨터를 시작하면 시간이 너무 빠르게 가요.  Time flies when you start using the computer.   \n",
       "3       나는 오늘 자정에 한국으로 돌아 가요.     I'm going back to Korea today at midnight.   \n",
       "4          나는 일어나자마자 화장실에 가요.         I go to bathroom as soon as I wake up.   \n",
       "\n",
       "  src_len tar_len  \n",
       "0                  \n",
       "1                  \n",
       "2                  \n",
       "3                  \n",
       "4                  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df['src_len'] = \"\"\n",
    "total_df['tar_len'] = \"\"\n",
    "total_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공백으로 구분해서 사용\n",
    "for idx in range(len(total_df)) :\n",
    "    text_eng = str(total_df.iloc[idx]['SRC'])\n",
    "\n",
    "    result_eng = len(text_eng.split())\n",
    "    total_df.at[idx, 'src_len'] = result_eng\n",
    "\n",
    "    text_fra = str(total_df.iloc[idx]['TRG'])\n",
    "    result_fra = len(text_fra.split())\n",
    "    total_df.at[idx, 'tar_len'] = result_fra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRG</th>\n",
       "      <th>SRC</th>\n",
       "      <th>src_len</th>\n",
       "      <th>tar_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>나는 매일 저녁 배트를 만나러 다락방으로 가요.</td>\n",
       "      <td>I go to the attic every evening to meet Bat.</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>선생님 이문장이 이해가 안 가요.</td>\n",
       "      <td>Sir, I don't understand this sentence here.</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>컴퓨터를 시작하면 시간이 너무 빠르게 가요.</td>\n",
       "      <td>Time flies when you start using the computer.</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>나는 오늘 자정에 한국으로 돌아 가요.</td>\n",
       "      <td>I'm going back to Korea today at midnight.</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>나는 일어나자마자 화장실에 가요.</td>\n",
       "      <td>I go to bathroom as soon as I wake up.</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          TRG                                            SRC  \\\n",
       "0  나는 매일 저녁 배트를 만나러 다락방으로 가요.   I go to the attic every evening to meet Bat.   \n",
       "1          선생님 이문장이 이해가 안 가요.    Sir, I don't understand this sentence here.   \n",
       "2    컴퓨터를 시작하면 시간이 너무 빠르게 가요.  Time flies when you start using the computer.   \n",
       "3       나는 오늘 자정에 한국으로 돌아 가요.     I'm going back to Korea today at midnight.   \n",
       "4          나는 일어나자마자 화장실에 가요.         I go to bathroom as soon as I wake up.   \n",
       "\n",
       "  src_len tar_len  \n",
       "0      10       7  \n",
       "1       7       5  \n",
       "2       8       6  \n",
       "3       8       6  \n",
       "4      10       4  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115000\n"
     ]
    }
   ],
   "source": [
    "print(len(total_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99006\n"
     ]
    }
   ],
   "source": [
    "total_df = total_df.drop_duplicates(subset=[\"SRC\"])\n",
    "print(len(total_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95453\n"
     ]
    }
   ],
   "source": [
    "total_df = total_df.drop_duplicates(subset=[\"TRG\"])\n",
    "print(len(total_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_within_len = (7 < total_df['src_len']) & (total_df['tar_len'] <= 20) &  (7 < total_df['tar_len']) & (total_df['src_len'] <= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21132"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df = total_df[is_within_len]\n",
    "len(total_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8192 entries, 38672 to 7829\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   TRG      8192 non-null   object\n",
      " 1   SRC      8192 non-null   object\n",
      " 2   src_len  8192 non-null   object\n",
      " 3   tar_len  8192 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 320.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data = total_df.sample(n=1024*8 , random_state=42)\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TRG        0\n",
       "SRC        0\n",
       "src_len    0\n",
       "tar_len    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_src = []\n",
    "\n",
    "for sentence in train_data['SRC'] :\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r\"([?.!,])\", \" \\1\" , sentence)\n",
    "    sentence = re.sub(r\"[' ']+\" , \" \" , sentence)\n",
    "    sentence = re.sub(r\"i'm\", 'i am', sentence)\n",
    "    sentence = re.sub(r\"he's\", 'he is', sentence)\n",
    "    sentence = re.sub(r\"she's\", 'she is', sentence)\n",
    "    sentence = re.sub(r\"it's\", 'it is', sentence)\n",
    "    sentence = re.sub(r\"that's\", 'that is', sentence)\n",
    "    sentence = re.sub(r\"what's\", 'what is', sentence)\n",
    "    sentence = re.sub(r\"where's\", 'where is', sentence)\n",
    "    sentence = re.sub(r\"how's\", 'how is', sentence)\n",
    "    sentence = re.sub(r\"\\'ll\", 'will', sentence)\n",
    "    sentence = re.sub(r\"\\'ve\", 'have', sentence)\n",
    "    sentence = re.sub(r\"\\'re\", 'are', sentence)\n",
    "    sentence = re.sub(r\"\\'d\", 'would', sentence)\n",
    "    sentence = re.sub(r\"won't\", 'will not', sentence)\n",
    "    sentence = re.sub(r\"can't\", 'cannot', sentence)\n",
    "    sentence = re.sub(r\"n't\", 'not', sentence)\n",
    "    sentence = re.sub(r\"n'\", 'ng', sentence)\n",
    "\n",
    "    sentence = re.sub(r\"[^a-z]+\" , ' ', sentence)\n",
    "    sentence = sentence.strip()\n",
    "    raw_src.append(sentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_trg = []\n",
    "for sentence in train_data['TRG'] :\n",
    "    sentence = re.sub(r\"[?.!,]\", \" \\1\" , sentence)\n",
    "    sentence = sentence.strip()\n",
    "    raw_trg.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8192"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['또한 좋은 의상을 만들고자하는 그녀의 노력에 감명을 받았어요 \\x01', '저는 상대방을 대할 때 항상 배려해주려 노력하고 솔직하게 대해요 \\x01', '그렇군요 \\x01 한국전자에서 요청한 변경 사항은 범위가 얼마나 돼요 \\x01', '공원 안에서 자전거를 빌릴 수 있는 곳이 있나요 \\x01', '페루라니 엄청나게 먼 나라인데 \\x01 그곳에서 사람들이 케이팝을 듣는다고 \\x01']\n",
      "['i m also impressed by her efforts to make good costumes', 'i always try to treat others in thoughtful and truthful ways', 'i see what is the range of modification requested by korea electronics', 'is there a place in the park where i can rent bikes', 'peru is a country so far away people listen to k pop there']\n"
     ]
    }
   ],
   "source": [
    "print(raw_trg[:5])\n",
    "print(raw_src[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(raw_src)\n",
    "df2 = pd.DataFrame(raw_trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.rename(columns={0:\"SRC\"}, inplace=True)\n",
    "df2.rename(columns={0:\"TRG\"}, inplace=True)\n",
    "train_df = pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_src = train_df['SRC']\n",
    "raw_trg = train_df['TRG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰 적용을 위한 전처리 부분\n",
    "special_tkns = \"<PAD> <SOS> <EOS> <CLS> <SEP> <MASK> \"\n",
    "src_sentence = raw_src.apply(lambda x : \"<CLS> \" + str(x) + \"<SEP>\")\n",
    "trg_sentence = raw_trg.apply(lambda x : str(x) + \"<SEP>\")\n",
    "\n",
    "filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
    "oov_token = '<unk>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이저 정의\n",
    "SRC_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)\n",
    "TRG_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)\n",
    "\n",
    "SRC_tokenizer.fit_on_texts(special_tkns + src_sentence)\n",
    "TRG_tokenizer.fit_on_texts(special_tkns + trg_sentence)\n",
    "\n",
    "n_enc_vocab = len(SRC_tokenizer.word_index) + 7\n",
    "n_dec_vocab = len(TRG_tokenizer.word_index) + 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8600, 21395)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_enc_vocab , n_dec_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [\n",
    "    \"It is winter and the weather is very cold.\",\n",
    "    \"Will this Christmas be a white Christmas?\",\n",
    "    \"Be careful not to catch a cold in winter\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input      : It is winter and the weather is very cold.\n",
      "txt_2_ids  : [[13, 14, 894, 15, 9, 1113, 14, 115, 716]]\n",
      "ids_2_txt  : it is winter and the weather is very cold \n",
      "\n",
      "Input      : Will this Christmas be a white Christmas?\n",
      "txt_2_ids  : [[29, 26, 1492, 27, 12, 705, 1492]]\n",
      "ids_2_txt  : will this christmas be a white christmas \n",
      "\n",
      "Input      : Be careful not to catch a cold in winter\n",
      "txt_2_ids  : [[27, 1248, 40, 10, 890, 12, 716, 17, 894]]\n",
      "ids_2_txt  : be careful not to catch a cold in winter \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in lines :\n",
    "    txt_2_ids = SRC_tokenizer.texts_to_sequences([line])\n",
    "    ids_2_txt = SRC_tokenizer.sequences_to_texts(txt_2_ids)\n",
    "    print(\"Input      :\", line)\n",
    "    print(\"txt_2_ids  :\", txt_2_ids)\n",
    "    print(\"ids_2_txt  :\", ids_2_txt[0], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [\n",
    "    \"딥 러닝 자연어 처리에서 역시 전처리는 어려워요\",\n",
    "    \"여러분들이 데이터 사이언티스트가 되어 현장에서 함께 하고 싶어요\",\n",
    "    \"오늘은 즐거운 불금입니다.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input      : 딥 러닝 자연어 처리에서 역시 전처리는 어려워요\n",
      "txt_2_ids  : [[1, 1, 1, 1, 735, 1, 11034]]\n",
      "ids_2_txt  : <unk> <unk> <unk> <unk> 역시 <unk> 어려워요 \n",
      "\n",
      "Input      : 여러분들이 데이터 사이언티스트가 되어 현장에서 함께 하고 싶어요\n",
      "txt_2_ids  : [[1, 17750, 1, 349, 13168, 71, 47, 123]]\n",
      "ids_2_txt  : <unk> 데이터 <unk> 되어 현장에서 함께 하고 싶어요 \n",
      "\n",
      "Input      : 오늘은 즐거운 불금입니다.\n",
      "txt_2_ids  : [[263, 786, 1]]\n",
      "ids_2_txt  : 오늘은 즐거운 <unk> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in lines :\n",
    "    txt_2_ids =  TRG_tokenizer.texts_to_sequences([line])\n",
    "    ids_2_txt = TRG_tokenizer.sequences_to_texts(txt_2_ids)\n",
    "    print(\"Input      :\", line)\n",
    "    print(\"txt_2_ids  :\", txt_2_ids)\n",
    "    print(\"ids_2_txt  :\", ids_2_txt[0], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 데이터의 길이를 맞춰주는 전처리\n",
    "tokenized_inputs = SRC_tokenizer.texts_to_sequences(src_sentence)\n",
    "tokenized_outputs = TRG_tokenizer.texts_to_sequences(trg_sentence)\n",
    "\n",
    "pad_idx = SRC_tokenizer.texts_to_sequences(['<PAD>'])\n",
    "\n",
    "tkn_sources = []\n",
    "tkn_targets = []\n",
    "\n",
    "for idx in range(len(tokenized_inputs)):\n",
    "    indexed_src_tkns = tokenized_inputs[idx] + [0] * (ENCODER_LEN - len(tokenized_inputs[idx]))\n",
    "    indexed_trg_tkns = [0] * len(tokenized_inputs[idx]) + tokenized_outputs[idx] + [0]*(ENCODER_LEN - len(tokenized_inputs[idx]) - len(tokenized_outputs[idx]))\n",
    "\n",
    "    tkn_sources.append(indexed_src_tkns)\n",
    "    tkn_targets.append(indexed_trg_tkns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list -> tf \n",
    "tensors_src = tf.cast(tkn_sources, dtype=tf.int64)\n",
    "tensors_trg = tf.cast(tkn_targets, dtype=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([8192, 61]), TensorShape([8192, 61]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors_src.shape , tensors_trg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(61,), dtype=int64, numpy=\n",
       "array([   2,    8,   42,  107, 1254,   78,  160, 2331,   10,   70,   68,\n",
       "       4264,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0], dtype=int64)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors_src[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(61,), dtype=int64, numpy=\n",
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,  199,   38, 3966, 6776,  485, 2820, 2821,  514,    8,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0], dtype=int64)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors_trg[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 아키텍처"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 파라미터 추가\n",
    "n_layers = 6 \n",
    "hid_dim = 128\n",
    "pf_dim = 1024\n",
    "n_heads = 8\n",
    "dropout = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = tf.data.Dataset.from_tensor_slices((tensors_src, tensors_trg))\n",
    "\n",
    "datasets = datasets.cache()\n",
    "datasets = datasets.shuffle(BUFFER_SIZE)\n",
    "datasets = datasets.batch(BATCH_SIZE)\n",
    "datasets = datasets.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" sinusoid position encoding \"\"\"\n",
    "def get_sinusoid_encoding_table(position, hid_dim) :\n",
    "    position = np.arange(position)[:, np.newaxis]\n",
    "    angle_rates = 1 / np.power(10000, (2 * (np.arange(hid_dim)[np.newaxis, :] // 2 )) / np.float32(hid_dim))\n",
    "    angle_rads = position * angle_rates\n",
    "\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 예시 \n",
    "\n",
    "sample_pos_encoding = get_sinusoid_encoding_table(50, 128)\n",
    "\n",
    "plt.pcolormesh(sample_pos_encoding._numpy()[0], cmap=\"RdBu\")\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 128))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" attention pad mask \"\"\"\n",
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    # (batch_size , 1, 1, key의 문장 길이)\n",
    "    return seq[:, tf.newaxis , tf.newaxis , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" attention decoder mask \"\"\"\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" scale dot product attention \"\"\"\n",
    "def ScaledDotProductAttention(query, key, value, mask) :\n",
    "    \"\"\"\n",
    "    query , key, value의 leading dimension은 동일해야 함\n",
    "    key, value에는 끝에서 두 번째 차원이 있어야 함(예: seq_len_k = seq_len_v)\n",
    "    MASK는 유형에 따라 모양이 다름\n",
    "\n",
    "    Args : \n",
    "        query : query.shape == (batch_size, n_heads, seq_len_q, depth)\n",
    "        key   : key.shape   == (batch_size, n_heads, seq_len_k, depth)\n",
    "        value : value.shape == (batch_size, n_heads , seq_len_v, depth_v)\n",
    "        mask  : mask.shape == (batch_size, n_heads, seq_len_q, seq_len_k)  # Default to None\n",
    "\n",
    "    return :\n",
    "        output , attention_weights\n",
    "    \"\"\"\n",
    "    # transpose_b=True : 곱하기 전에 트랜스포즈(전치)\n",
    "    matmul_pk = tf.matmul(query, key, transpose_b=True )\n",
    "    #(..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # scale matmul_qk \n",
    "    dk = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_pk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor\n",
    "    if mask is not None :\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "    \n",
    "    # softmax 정규화\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis= -1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, value) # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Multi head attention \"\"\"\n",
    "class MultiHeadAttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, hid_dim, n_heads):\n",
    "        super(MultiHeadAttentionLayer, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "        assert hid_dim % self.n_heads == 0\n",
    "        self.hid_dim = hid_dim\n",
    "\n",
    "        self.depth = int(hid_dim / self.n_heads)\n",
    "\n",
    "        # WQ, WK, WV에 해당하는 밀집층 정의\n",
    "        self.q_linear = tf.keras.layers.Dense(hid_dim)\n",
    "        self.k_linear = tf.keras.layers.Dense(hid_dim)\n",
    "        self.v_linear = tf.keras.layers.Dense(hid_dim)\n",
    "\n",
    "        # WO에 해당하는 밀집층 정의\n",
    "        self.out = tf.keras.layers.Dense(hid_dim)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size) :\n",
    "        \"\"\" \n",
    "        마지막 차원을 변경 (n_heads, depth)\n",
    "        \"\"\"\n",
    "        inputs = tf.reshape(inputs, (batch_size, -1, self.n_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0,2,1,3])\n",
    "    \n",
    "    def call(self, value, key, query, mask):\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # step1 : WQ, WK, WV에 해당하는 밀집층 지나기\n",
    "        query = self.q_linear(query)\n",
    "        key = self.k_linear(key)\n",
    "        value = self.v_linear(value)\n",
    "\n",
    "        # step2 : 헤드 나누기\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # step3 : 스케일드 닷 프로덕트 어텐션\n",
    "        scaled_attention, attention_weights = ScaledDotProductAttention(query, key, value, mask)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # step4 : 헤드 연결\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.hid_dim))\n",
    "\n",
    "        # step5 : WO 해당하는 밀집층 지나기\n",
    "        outputs = self.out(concat_attention)\n",
    "\n",
    "        return outputs, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" feed forward \"\"\"\n",
    "class PositionwiseFeedforwardLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, hid_dim, pf_dim):\n",
    "        super(PositionwiseFeedforwardLayer, self).__init__()\n",
    "        self.linear_1 = tf.keras.layers.Dense(pf_dim, activation='relu')\n",
    "        self.linear_2 = tf.keras.layers.Dense(hid_dim)\n",
    "\n",
    "    def forword(self, attention):\n",
    "        output = self.linear_1(attention)\n",
    "        output = self.linear_2(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" decoder layer \"\"\"\n",
    "class DecoderLayer(tf.keras.layers.Layer) :\n",
    "    def __init__(self, pf_dim, hid_dim, n_heads, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.attn = MultiHeadAttentionLayer(hid_dim, n_heads)\n",
    "\n",
    "        self.ffn = PositionwiseFeedforwardLayer(hid_dim, pf_dim)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.dropout3 = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, inputs, training, look_ahead_mask) :\n",
    "        attention1, attn_weights_block1 = self.attn(inputs, inputs, inputs, look_ahead_mask)\n",
    "        attention1 = self.dropout1(attention1, training= training)\n",
    "        attention1 = self.layernorm1(inputs + attention1)\n",
    "\n",
    "        ffn_outputs = self.ffn(attention1)\n",
    "        ffn_outputs = self.dropout3(ffn_outputs, training = training)\n",
    "        ffn_outputs = self.layernorm3(attention1 + ffn_outputs)\n",
    "\n",
    "        return ffn_outputs , attn_weights_block1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" decoder \"\"\"\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_dec_vocab, n_layers, pf_dim, hid_dim, n_heads, maximum_position_encoding, dropout) :\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = tf.keras.layers.Embedding(n_dec_vocab, hid_dim)\n",
    "        self.pos_encoding = get_sinusoid_encoding_table(maximum_position_encoding, hid_dim)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(pf_dim, hid_dim, n_heads, dropout) for _ in range(n_layers)]\n",
    "\n",
    "        # 수정\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, dec_input, training, look_ahead_mask):\n",
    "        seq_len = tf.shape(dec_input)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        emb = self.embedding(dec_input)\n",
    "        emb*= tf.math.sqrt(tf.cast(self.hid_dim, tf.float32))\n",
    "        emb+= self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        output = self.dropout(emb , training= training)\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            output, block1 = self.dec_layers[i](output, training, look_ahead_mask)\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(tar) :\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    look_ahead_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return look_ahead_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 정의\n",
    "\"\"\" transformer \"\"\"\n",
    "class GPT2(tf.keras.Model) :\n",
    "    def __init__(self, n_enc_vocab, n_dec_vocab, n_layers, pf_dim, hid_dim, n_heads, pe_input, pe_target, dropout):\n",
    "        super(GPT2, self).__init__()\n",
    "\n",
    "        self.decoder = Decoder(n_dec_vocab,\n",
    "                               n_layers, pf_dim, hid_dim, n_heads, \n",
    "                               pe_target, dropout)\n",
    "        \n",
    "        self.fin_output = tf.keras.layers.Dense(n_dec_vocab)\n",
    "\n",
    "    def call(self, inp, training, look_ahead_mask) :\n",
    "        dec_output, attention_weights = self.decoder(inp, training, look_ahead_mask)\n",
    "\n",
    "        final_output = self.fin_output(dec_output)\n",
    "\n",
    "        return final_output, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_) / tf.reduce_sum(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01 \n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1 = 0.9, beta_2 = 0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_function(real, pred):\n",
    "    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    accuracies = tf.math.logical_and(mask, accuracies)\n",
    "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(accuracies) / tf.reduce_sum(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Training and checkpointing \"\"\"\n",
    "\n",
    "model = GPT2(\n",
    "    n_enc_vocab=n_enc_vocab , \n",
    "    n_dec_vocab=n_dec_vocab , \n",
    "    n_layers=n_layers , \n",
    "    pf_dim=pf_dim , \n",
    "    hid_dim=hid_dim, \n",
    "    n_heads=n_heads,\n",
    "    pe_input= 512 ,\n",
    "    pe_target= 512 , \n",
    "    dropout= dropout\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(model=model, optimizer= optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint :\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print(\"Lastest checkpoint restored!!\")\n",
    "# import logging\n",
    "# logging.DEBUG('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "    combined_mask = create_masks(inp)\n",
    "\n",
    "    with tf.GradientTape() as tape :\n",
    "        predictions, _ = model(inp, True, combined_mask)\n",
    "        loss = loss_function(tar, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(accuracy_function(tar, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_27444\\142244732.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  with tqdm_notebook(total=len(datasets), desc = f'Train {epoch+1}') as pbar :\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4588da933e4a0eaedef85c2fba6e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_27444\\3924528485.py\", line 6, in train_step  *\n        predictions, _ = model(inp, True, combined_mask)\n    File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_filecwljnz7p.py\", line 10, in tf__call\n        (dec_output, attention_weights) = ag__.converted_call(ag__.ld(self).decoder, (ag__.ld(inp), ag__.ld(training), ag__.ld(look_ahead_mask)), None, fscope)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_fileqv8hqgw_.py\", line 33, in tf__call\n        ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(self).n_layers,), None, fscope), None, loop_body, get_state, set_state, ('output',), {'iterate_names': 'i'})\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_fileqv8hqgw_.py\", line 29, in loop_body\n        (output, block1) = ag__.converted_call(ag__.ld(self).dec_layers[ag__.ld(i)], (ag__.ld(output), ag__.ld(training), ag__.ld(look_ahead_mask)), None, fscope)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_files64w0xxv.py\", line 10, in tf__call\n        (attention1, attn_weights_block1) = ag__.converted_call(ag__.ld(self).attn, (ag__.ld(inputs), ag__.ld(inputs), ag__.ld(inputs), ag__.ld(look_ahead_mask)), None, fscope)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_fileoogvb3ty.py\", line 17, in tf__call\n        (scaled_attention, attention_weights) = ag__.converted_call(ag__.ld(ScaledDotProductAttention), (ag__.ld(query), ag__.ld(key), ag__.ld(value), ag__.ld(mask)), None, fscope)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_file1at9d0_i.py\", line 25, in tf__ScaledDotProductAttention\n        dk = ag__.converted_call(ag__.ld(tf).cast, (ag__.converted_call(ag__.ld(tf).shape, (ag__.ld(key),), None, fscope)[-1].tf.float32,), None, fscope)\n\n    AttributeError: Exception encountered when calling layer 'gpt2' (type GPT2).\n    \n    in user code:\n    \n        File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_27444\\4084406977.py\", line 14, in call  *\n            dec_output, attention_weights = self.decoder(inp, training, look_ahead_mask)\n        File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_fileqv8hqgw_.py\", line 33, in tf__call\n            ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(self).n_layers,), None, fscope), None, loop_body, get_state, set_state, ('output',), {'iterate_names': 'i'})\n        File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_fileqv8hqgw_.py\", line 29, in loop_body\n            (output, block1) = ag__.converted_call(ag__.ld(self).dec_layers[ag__.ld(i)], (ag__.ld(output), ag__.ld(training), ag__.ld(look_ahead_mask)), None, fscope)\n        File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_files64w0xxv.py\", line 10, in tf__call\n            (attention1, attn_weights_block1) = ag__.converted_call(ag__.ld(self).attn, (ag__.ld(inputs), ag__.ld(inputs), ag__.ld(inputs), ag__.ld(look_ahead_mask)), None, fscope)\n        File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_fileoogvb3ty.py\", line 17, in tf__call\n            (scaled_attention, attention_weights) = ag__.converted_call(ag__.ld(ScaledDotProductAttention), (ag__.ld(query), ag__.ld(key), ag__.ld(value), ag__.ld(mask)), None, fscope)\n        File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_file1at9d0_i.py\", line 25, in tf__ScaledDotProductAttention\n            dk = ag__.converted_call(ag__.ld(tf).cast, (ag__.converted_call(ag__.ld(tf).shape, (ag__.ld(key),), None, fscope)[-1].tf.float32,), None, fscope)\n    \n        AttributeError: Exception encountered when calling layer 'decoder' (type Decoder).\n        \n        in user code:\n        \n            File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_27444\\3466053320.py\", line 27, in call  *\n                output, block1 = self.dec_layers[i](output, training, look_ahead_mask)\n            File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n            File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_files64w0xxv.py\", line 10, in tf__call\n                (attention1, attn_weights_block1) = ag__.converted_call(ag__.ld(self).attn, (ag__.ld(inputs), ag__.ld(inputs), ag__.ld(inputs), ag__.ld(look_ahead_mask)), None, fscope)\n            File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_fileoogvb3ty.py\", line 17, in tf__call\n                (scaled_attention, attention_weights) = ag__.converted_call(ag__.ld(ScaledDotProductAttention), (ag__.ld(query), ag__.ld(key), ag__.ld(value), ag__.ld(mask)), None, fscope)\n            File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_file1at9d0_i.py\", line 25, in tf__ScaledDotProductAttention\n                dk = ag__.converted_call(ag__.ld(tf).cast, (ag__.converted_call(ag__.ld(tf).shape, (ag__.ld(key),), None, fscope)[-1].tf.float32,), None, fscope)\n        \n            AttributeError: Exception encountered when calling layer 'decoder_layer' (type DecoderLayer).\n            \n            in user code:\n            \n                File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_27444\\3315783466.py\", line 19, in call  *\n                    attention1, attn_weights_block1 = self.attn(inputs, inputs, inputs, look_ahead_mask)\n                File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n                    raise e.with_traceback(filtered_tb) from None\n                File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_fileoogvb3ty.py\", line 17, in tf__call\n                    (scaled_attention, attention_weights) = ag__.converted_call(ag__.ld(ScaledDotProductAttention), (ag__.ld(query), ag__.ld(key), ag__.ld(value), ag__.ld(mask)), None, fscope)\n                File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_file1at9d0_i.py\", line 25, in tf__ScaledDotProductAttention\n                    dk = ag__.converted_call(ag__.ld(tf).cast, (ag__.converted_call(ag__.ld(tf).shape, (ag__.ld(key),), None, fscope)[-1].tf.float32,), None, fscope)\n            \n                AttributeError: Exception encountered when calling layer 'multi_head_attention_layer' (type MultiHeadAttentionLayer).\n                \n                in user code:\n                \n                    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_27444\\4203886506.py\", line 40, in call  *\n                        scaled_attention, attention_weights = ScaledDotProductAttention(query, key, value, mask)\n                    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_27444\\580998220.py\", line 22, in ScaledDotProductAttention  *\n                        dk = tf.cast(tf.shape(key)[-1]. tf.float32)\n                \n                    AttributeError: 'Tensor' object has no attribute 'tf'\n                \n                \n                Call arguments received by layer 'multi_head_attention_layer' (type MultiHeadAttentionLayer):\n                  • value=tf.Tensor(shape=(256, 61, 128), dtype=float32)\n                  • key=tf.Tensor(shape=(256, 61, 128), dtype=float32)\n                  • query=tf.Tensor(shape=(256, 61, 128), dtype=float32)\n                  • mask=tf.Tensor(shape=(256, 1, 61, 61), dtype=float32)\n            \n            \n            Call arguments received by layer 'decoder_layer' (type DecoderLayer):\n              • inputs=tf.Tensor(shape=(256, 61, 128), dtype=float32)\n              • training=True\n              • look_ahead_mask=tf.Tensor(shape=(256, 1, 61, 61), dtype=float32)\n        \n        \n        Call arguments received by layer 'decoder' (type Decoder):\n          • dec_input=tf.Tensor(shape=(256, 61), dtype=int64)\n          • training=True\n          • look_ahead_mask=tf.Tensor(shape=(256, 1, 61, 61), dtype=float32)\n    \n    \n    Call arguments received by layer 'gpt2' (type GPT2):\n      • inp=tf.Tensor(shape=(256, 61), dtype=int64)\n      • training=True\n      • look_ahead_mask=tf.Tensor(shape=(256, 1, 61, 61), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27444\\142244732.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'Train {epoch+1}'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpbar\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mpbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filegzw7qpw_.py\u001b[0m in \u001b[0;36mtf__train_step\u001b[1;34m(inp, tar)\u001b[0m\n\u001b[0;32m      8\u001b[0m                 \u001b[0mcombined_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                     \u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filecwljnz7p.py\u001b[0m in \u001b[0;36mtf__call\u001b[1;34m(self, inp, training, look_ahead_mask)\u001b[0m\n\u001b[0;32m      8\u001b[0m                 \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                 \u001b[1;33m(\u001b[0m\u001b[0mdec_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_weights\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlook_ahead_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m                 \u001b[0mfinal_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfin_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileqv8hqgw_.py\u001b[0m in \u001b[0;36mtf__call\u001b[1;34m(self, dec_input, training, look_ahead_mask)\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[0mblock1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'block1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                 \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'output'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'iterate_names'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'i'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileqv8hqgw_.py\u001b[0m in \u001b[0;36mloop_body\u001b[1;34m(itr)\u001b[0m\n\u001b[0;32m     27\u001b[0m                     \u001b[1;32mnonlocal\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m                     \u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdec_layers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlook_ahead_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m                     \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'decoder_layer{}_block1'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[0mblock1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'block1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_files64w0xxv.py\u001b[0m in \u001b[0;36mtf__call\u001b[1;34m(self, inputs, training, look_ahead_mask)\u001b[0m\n\u001b[0;32m      8\u001b[0m                 \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                 \u001b[1;33m(\u001b[0m\u001b[0mattention1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_weights_block1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlook_ahead_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m                 \u001b[0mattention1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[0mattention1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayernorm1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileoogvb3ty.py\u001b[0m in \u001b[0;36mtf__call\u001b[1;34m(self, value, key, query, mask)\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit_heads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit_heads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                 \u001b[1;33m(\u001b[0m\u001b[0mscaled_attention\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_weights\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mScaledDotProductAttention\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m                 \u001b[0mscaled_attention\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaled_attention\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[0mconcat_attention\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaled_attention\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhid_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file1at9d0_i.py\u001b[0m in \u001b[0;36mtf__ScaledDotProductAttention\u001b[1;34m(query, key, value, mask)\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[0mmatmul_pk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[0mdk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m                 \u001b[0mscaled_attention_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatmul_pk\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_27444\\3924528485.py\", line 6, in train_step  *\n        predictions, _ = model(inp, True, combined_mask)\n    File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_filecwljnz7p.py\", line 10, in tf__call\n        (dec_output, attention_weights) = ag__.converted_call(ag__.ld(self).decoder, (ag__.ld(inp), ag__.ld(training), ag__.ld(look_ahead_mask)), None, fscope)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_fileqv8hqgw_.py\", line 33, in tf__call\n        ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(self).n_layers,), None, fscope), None, loop_body, get_state, set_state, ('output',), {'iterate_names': 'i'})\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_fileqv8hqgw_.py\", line 29, in loop_body\n        (output, block1) = ag__.converted_call(ag__.ld(self).dec_layers[ag__.ld(i)], (ag__.ld(output), ag__.ld(training), ag__.ld(look_ahead_mask)), None, fscope)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_files64w0xxv.py\", line 10, in tf__call\n        (attention1, attn_weights_block1) = ag__.converted_call(ag__.ld(self).attn, (ag__.ld(inputs), ag__.ld(inputs), ag__.ld(inputs), ag__.ld(look_ahead_mask)), None, fscope)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_fileoogvb3ty.py\", line 17, in tf__call\n        (scaled_attention, attention_weights) = ag__.converted_call(ag__.ld(ScaledDotProductAttention), (ag__.ld(query), ag__.ld(key), ag__.ld(value), ag__.ld(mask)), None, fscope)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_file1at9d0_i.py\", line 25, in tf__ScaledDotProductAttention\n        dk = ag__.converted_call(ag__.ld(tf).cast, (ag__.converted_call(ag__.ld(tf).shape, (ag__.ld(key),), None, fscope)[-1].tf.float32,), None, fscope)\n\n    AttributeError: Exception encountered when calling layer 'gpt2' (type GPT2).\n    \n    in user code:\n    \n        File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_27444\\4084406977.py\", line 14, in call  *\n            dec_output, attention_weights = self.decoder(inp, training, look_ahead_mask)\n        File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_fileqv8hqgw_.py\", line 33, in tf__call\n            ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(self).n_layers,), None, fscope), None, loop_body, get_state, set_state, ('output',), {'iterate_names': 'i'})\n        File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_fileqv8hqgw_.py\", line 29, in loop_body\n            (output, block1) = ag__.converted_call(ag__.ld(self).dec_layers[ag__.ld(i)], (ag__.ld(output), ag__.ld(training), ag__.ld(look_ahead_mask)), None, fscope)\n        File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_files64w0xxv.py\", line 10, in tf__call\n            (attention1, attn_weights_block1) = ag__.converted_call(ag__.ld(self).attn, (ag__.ld(inputs), ag__.ld(inputs), ag__.ld(inputs), ag__.ld(look_ahead_mask)), None, fscope)\n        File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_fileoogvb3ty.py\", line 17, in tf__call\n            (scaled_attention, attention_weights) = ag__.converted_call(ag__.ld(ScaledDotProductAttention), (ag__.ld(query), ag__.ld(key), ag__.ld(value), ag__.ld(mask)), None, fscope)\n        File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_file1at9d0_i.py\", line 25, in tf__ScaledDotProductAttention\n            dk = ag__.converted_call(ag__.ld(tf).cast, (ag__.converted_call(ag__.ld(tf).shape, (ag__.ld(key),), None, fscope)[-1].tf.float32,), None, fscope)\n    \n        AttributeError: Exception encountered when calling layer 'decoder' (type Decoder).\n        \n        in user code:\n        \n            File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_27444\\3466053320.py\", line 27, in call  *\n                output, block1 = self.dec_layers[i](output, training, look_ahead_mask)\n            File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n            File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_files64w0xxv.py\", line 10, in tf__call\n                (attention1, attn_weights_block1) = ag__.converted_call(ag__.ld(self).attn, (ag__.ld(inputs), ag__.ld(inputs), ag__.ld(inputs), ag__.ld(look_ahead_mask)), None, fscope)\n            File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_fileoogvb3ty.py\", line 17, in tf__call\n                (scaled_attention, attention_weights) = ag__.converted_call(ag__.ld(ScaledDotProductAttention), (ag__.ld(query), ag__.ld(key), ag__.ld(value), ag__.ld(mask)), None, fscope)\n            File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_file1at9d0_i.py\", line 25, in tf__ScaledDotProductAttention\n                dk = ag__.converted_call(ag__.ld(tf).cast, (ag__.converted_call(ag__.ld(tf).shape, (ag__.ld(key),), None, fscope)[-1].tf.float32,), None, fscope)\n        \n            AttributeError: Exception encountered when calling layer 'decoder_layer' (type DecoderLayer).\n            \n            in user code:\n            \n                File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_27444\\3315783466.py\", line 19, in call  *\n                    attention1, attn_weights_block1 = self.attn(inputs, inputs, inputs, look_ahead_mask)\n                File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n                    raise e.with_traceback(filtered_tb) from None\n                File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_fileoogvb3ty.py\", line 17, in tf__call\n                    (scaled_attention, attention_weights) = ag__.converted_call(ag__.ld(ScaledDotProductAttention), (ag__.ld(query), ag__.ld(key), ag__.ld(value), ag__.ld(mask)), None, fscope)\n                File \"C:\\Users\\user\\AppData\\Local\\Temp\\__autograph_generated_file1at9d0_i.py\", line 25, in tf__ScaledDotProductAttention\n                    dk = ag__.converted_call(ag__.ld(tf).cast, (ag__.converted_call(ag__.ld(tf).shape, (ag__.ld(key),), None, fscope)[-1].tf.float32,), None, fscope)\n            \n                AttributeError: Exception encountered when calling layer 'multi_head_attention_layer' (type MultiHeadAttentionLayer).\n                \n                in user code:\n                \n                    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_27444\\4203886506.py\", line 40, in call  *\n                        scaled_attention, attention_weights = ScaledDotProductAttention(query, key, value, mask)\n                    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_27444\\580998220.py\", line 22, in ScaledDotProductAttention  *\n                        dk = tf.cast(tf.shape(key)[-1]. tf.float32)\n                \n                    AttributeError: 'Tensor' object has no attribute 'tf'\n                \n                \n                Call arguments received by layer 'multi_head_attention_layer' (type MultiHeadAttentionLayer):\n                  • value=tf.Tensor(shape=(256, 61, 128), dtype=float32)\n                  • key=tf.Tensor(shape=(256, 61, 128), dtype=float32)\n                  • query=tf.Tensor(shape=(256, 61, 128), dtype=float32)\n                  • mask=tf.Tensor(shape=(256, 1, 61, 61), dtype=float32)\n            \n            \n            Call arguments received by layer 'decoder_layer' (type DecoderLayer):\n              • inputs=tf.Tensor(shape=(256, 61, 128), dtype=float32)\n              • training=True\n              • look_ahead_mask=tf.Tensor(shape=(256, 1, 61, 61), dtype=float32)\n        \n        \n        Call arguments received by layer 'decoder' (type Decoder):\n          • dec_input=tf.Tensor(shape=(256, 61), dtype=int64)\n          • training=True\n          • look_ahead_mask=tf.Tensor(shape=(256, 1, 61, 61), dtype=float32)\n    \n    \n    Call arguments received by layer 'gpt2' (type GPT2):\n      • inp=tf.Tensor(shape=(256, 61), dtype=int64)\n      • training=True\n      • look_ahead_mask=tf.Tensor(shape=(256, 1, 61, 61), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPRCHS):\n",
    "    train_loss.reset_state()\n",
    "\n",
    "    with tqdm_notebook(total=len(datasets), desc = f'Train {epoch+1}') as pbar :\n",
    "        for (batch, (inp, tar)) in enumerate(datasets):\n",
    "            train_step(inp, tar)\n",
    "\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix_str(f\"Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}\")\n",
    "\n",
    "    print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "\n",
    "ckpt_save_path = ckpt_manager.save()\n",
    "print('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
